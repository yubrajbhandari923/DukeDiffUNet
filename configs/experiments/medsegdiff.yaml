
# TODO:
#  - Add grad accumulation support and micro-batch support if necessary


# ───────────────────────────────────────────────────────────
# Basic experiment metadata
experiment:
  name: "MedSegDiff"
  version: 1.1
  description: "MedsegDiff3D with same parameters as before but dims=3"
  tags: ["MedSegDiff3D", "3D"]

# ───────────────────────────────────────────────────────────
# Global seed for reproducibility
seed: 42

# ───────────────────────────────────────────────────────────
# Logging & monitoring
logging:
  use_aim:       true
  aim_repo:      "/home/yb107/cvpr2025/DukeDiffSeg/aim/"
  log_interval:  10       # iterations
  aim_ui_port:   43800

# ───────────────────────────────────────────────────────────
# Data & DataLoader settings
data:
  description:        "Abdomen 1K dataset for segmentation"
  # cache_dir:          "/NAS/user_data/user/yb107/cache_dir"
  cache_dir:          "/data/usr/yb107/cache_3d"
  orientation:        "RAS"
  pixdim:             [2.0, 2.0, 3.0]
  roi_size:           [96, 96, 96]
  slice_axis:         -1
  
  train_jsonl:        "/home/yb107/cvpr2025/DukeDiffSeg/data/json/abdomen_1k_train_updated.jsonl"
  batch_size:         4
  num_workers:        8
  micro_batch_size:   1      # for gradient accumulation # Not implemented yet

  val_jsonl:          "/home/yb107/cvpr2025/DukeDiffSeg/data/json/abdomen_1k_val_updated.jsonl"
  val_batch_size:     1
  val_num_workers:    4

# ───────────────────────────────────────────────────────────
# Training hyperparameters
training:
  device:              "cuda"
  epochs:              5000
  accumulate_grad_steps: 1
  save_dir:            "/home/yb107/cvpr2025/DukeDiffSeg/outputs"
  save_interval:       5      # epochs
  resume:              null # Path to checkpoint to resume from (set to null to not resume)

# ───────────────────────────────────────────────────────────
# Optimizer & scheduler
optimizer:
  name:       "AdamW"
  lr:         1e-4
  weight_decay: 0
  set_to_none: false  # Set optimizer parameters to None for memory efficiency

lr_scheduler:
  name:       "CosineAnnealingLR"
  T_max:      50

# ───────────────────────────────────────────────────────────
# Evaluation & early stopping
evaluation:
  validation_interval:     10        # epochs
  validation_max_num_samples: 32 
  metrics:               ["dice", "hausdorff"]
  early_stopping:
    enable: true
    patience: 20
  visualize:             true
  visualize_every_iter:  1 
  visualize_interval:    1
  save_predictions:      true
  save_pred_interval:    1

# ───────────────────────────────────────────────────────────
# Model architecture (easy to swap out a different 'model.params' block)
model:
  name:       "MedSegDiff"       # used to select your Python class
  params:
    # UNet backbone
    image_size:        256  # Size of the input image (e.g., 64, 128, 256)
    num_channels:      128
    num_res_blocks:    2
    channel_mult:      ""  # Default channel multiplier
    learn_sigma:      true 
    class_cond:        false
    attention_resolutions: "16"
    in_ch:            2 # https://github.com/SuperMedIntel/MedSegDiff/blob/master/scripts/segmentation_train.py: line 49
    out_ch:            1 
    num_heads:         1
    num_head_channels: -1
    num_heads_upsample: -1
    dropout:           0.0
    resblock_updown:   false
    use_fp16:          false
    use_new_attention_order: false
    version:          "new"

    use_checkpoint:    false  # Enable gradient checkpointing for memory efficiency
    use_scale_shift_norm: false  # Use scale-shift normalization
    dims:            3  # Yubraj Added, set to 3 for 3D segmentation

    ema_rate:          0.99

    # Inference-specific parameters
    n_rounds: 1  

# ───────────────────────────────────────────────────────────
# Diffusion-specific hyperparameters
diffusion:
  diffusion_steps:   1000
  learn_sigma:       false
  noise_schedule:    "linear"
  use_kl:            false
  predict_xstart:    false
  rescale_timesteps: false
  rescale_learned_sigmas: false
  dpm_solver:        false # Use DPM-Solver for improved sampling
  timestep_respacing: ""

  schedule_sampler:
    name: "uniform"
    max_steps: 1000
 
  clip_denoised:     true
  lr_anneal_steps:   0

  ddpm_solver:       false
  ddim:              false

# ───────────────────────────────────────────────────────────
# Mixed-precision & AMP settings
amp:
  enabled:           false
  fp16_scale_growth: 1e-3
